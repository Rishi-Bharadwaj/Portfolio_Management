{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c89636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pandas.tseries.offsets import BDay\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "from datetime import datetime, date, timedelta\n",
    "import random\n",
    "import yfinance as yf\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da78c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75048e3949874eeea6e2265238bb1afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "torch.cuda.set_device(0)  # Sets default to GPU 0\n",
    "device=torch.device(\"cuda:0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \n",
    "    model_id,\n",
    "    device_map={\"\": 0},             # auto-distributes across GPUs\n",
    "    torch_dtype=\"auto\",            # picks bf16 or fp16 depending on availability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6cf14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Technical_Analyst:\n",
    "\n",
    "    def __init__(self, tickers, start_date, end_date, min_lookback_bdays=50, ind_max_window=50):\n",
    "        self.tickers = [tickers] if isinstance(tickers,str) else tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        start_dt = self.to_date(start_date)\n",
    "        end_dt   = self.to_date(end_date)\n",
    "\n",
    "        # Ensure start <= end\n",
    "        if end_dt < start_dt:\n",
    "            start_dt, end_dt = end_dt, start_dt\n",
    "\n",
    "        # Ensure at least N business days in the analysis window\n",
    "        min_start_dt = (pd.Timestamp(end_dt) - BDay(min_lookback_bdays)).date()\n",
    "        if (end_dt - start_dt).days < min_lookback_bdays:\n",
    "            start_dt = min_start_dt\n",
    "\n",
    "        # Keep analysis window (as strings, handy for APIs)\n",
    "        self.start_date = start_dt.strftime(\"%Y-%m-%d\")\n",
    "        self.end_date   = end_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Fetch window: pull extra history so indicators with large windows are valid\n",
    "        buffer_bdays = ind_max_window + 5  # small cushion\n",
    "        fetch_start_dt = (pd.Timestamp(start_dt) - BDay(buffer_bdays)).date()\n",
    "        self.fetch_start = fetch_start_dt.strftime(\"%Y-%m-%d\")\n",
    "        self.generate_df()\n",
    "        self.generate_indicators()\n",
    "        self.generate_technical_prompt()\n",
    "        \n",
    "    def generate_df(self):\n",
    "        self.data = yf.download(self.tickers, start=self.start_date, end=self.end_date)\n",
    "\n",
    "    def to_date(self, d):\n",
    "            if isinstance(d, date):\n",
    "                return d\n",
    "            if isinstance(d, str):\n",
    "                return datetime.strptime(d, \"%Y-%m-%d\").date()\n",
    "            # pandas Timestamp etc.\n",
    "            return pd.Timestamp(d).date()\n",
    "    \n",
    "    def compute_rsi(self, close, period=14):\n",
    "        delta = close.diff()\n",
    "\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=period).mean()\n",
    "        avg_loss = loss.rolling(window=period).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def compute_obv(self, close, volume):\n",
    "        direction = close.diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "        obv = (volume * direction).fillna(0).cumsum()\n",
    "        return obv\n",
    "    \n",
    "    def generate_indicators(self):\n",
    "        self.indicators_processed={}\n",
    "        for ticker in self.tickers:\n",
    "            temp=pd.DataFrame()\n",
    "            temp[\"SMA_5\"] = self.data['Close'][ticker].rolling(5).mean()\n",
    "            temp[\"SMA_15\"] = self.data['Close'][ticker].rolling(15).mean()\n",
    "            temp[\"SMA_50\"] = self.data['Close'][ticker].rolling(50).mean()\n",
    "\n",
    "            temp['EMA_5'] = self.data['Close'][ticker].ewm(span=5).mean()\n",
    "            temp['EMA_10'] = self.data['Close'][ticker].ewm(span=10).mean()\n",
    "            temp['EMA_50'] = self.data['Close'][ticker].ewm(span=50).mean()\n",
    "            temp[\"Date\"] = self.data['Close'][ticker].index\n",
    "            temp[\"RSI\"]=self.compute_rsi(self.data['Close'][ticker])\n",
    "            temp[\"OBV\"]=self.compute_obv(self.data['Close'][ticker], self.data['Volume'][ticker])\n",
    "            self.indicators_processed[ticker]=temp\n",
    "            \n",
    "    def generate_technical_prompt(self):\n",
    "\n",
    "        prompt = f\"\"\" Choose a recommendation for each stock. Respond in a vector of floats between [-1,1], -1 being Short and 1 being Strong Buy. \n",
    "Make these decisions based solely on the technical indicators given below for each stock. Return only the vector, no explanation is needed.\n",
    " You MUST return the vector at the end in this format [company1,company2,...companyn]: [Value1,Value2,Valuen]\"\"\"\n",
    "        for ticker in self.tickers:\n",
    "            latest=self.indicators_processed[ticker].iloc[-1]\n",
    "            partial_stats= f\"\"\"Technical Indicators for {ticker}:\n",
    "            SMA 5: {latest['SMA_5']:.2f}\n",
    "            SMA 15: {latest['SMA_15']:.2f}\n",
    "            SMA 50: {latest['SMA_50']:.2f}\n",
    "\n",
    "            EMA 5: {latest['EMA_5']:.2f}\n",
    "            EMA 10: {latest['EMA_10']:.2f}\n",
    "            EMA 50: {latest['EMA_50']:.2f}\n",
    "\n",
    "            RSI: {latest['RSI']:.2f}\n",
    "            OBV: {latest['OBV']:,.0f}\n",
    "            /n/n\"\"\"\n",
    "            prompt+=partial_stats\n",
    "        self.prompt=prompt\n",
    "        return self.prompt \n",
    "    \n",
    "    def generate_response(self):\n",
    "        prompt = self.prompt\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert technical analyst. Analyze stocks to the best of your ability.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        self.response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return self.response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b5dbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fundamental_Analyst:\n",
    "\n",
    "    def __init__(self, tickers, start_date, end_date):\n",
    "        self.tickers = list(tickers) if isinstance(tickers,str) else tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "        start_year = datetime.strptime(start_date, \"%Y-%m-%d\").year\n",
    "        end_year = datetime.strptime(end_date, \"%Y-%m-%d\").year\n",
    "        self.years = list(range(start_year, end_year + 1))\n",
    "        data_processed={}\n",
    "        for ticker in self.tickers:\n",
    "            metric_data, gaap_data=self.get_data(ticker)\n",
    "            data_processed[ticker]=self.get_financial_info(metric_data,gaap_data)\n",
    "        self.data_processed=data_processed\n",
    "        self.generate_prompt()\n",
    "        \n",
    "    def get_data(self,ticker):\n",
    "        api_key = \"d1l719pr01qt4thec1pgd1l719pr01qt4thec1q0\"\n",
    "        url = f\"https://finnhub.io/api/v1/stock/metric?symbol={ticker}&token={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        metric_data=response.json()\n",
    "        url = f\"https://finnhub.io/api/v1/stock/financials-reported?symbol={ticker}&token={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        gaap_data=response.json()\n",
    "        return metric_data,gaap_data\n",
    "\n",
    "    def find_us_gaap_entry(self, gaap_data, parameter, year):\n",
    "        for dic in gaap_data['data']:\n",
    "            if dic.get('year') == year:\n",
    "                for section in ['ic', 'bs', 'cf']:  # income statement, balance sheet, cash flow\n",
    "                    for entry in dic.get('report', {}).get(section, []):\n",
    "                        if parameter in entry.values():\n",
    "                            return entry.get('value')\n",
    "        return None\n",
    "\n",
    "    def find_metric_by_year(self,metric_data, parameter, year):\n",
    "        series = metric_data.get('series', {}).get('annual', {}).get(parameter, [])\n",
    "        for item in series:\n",
    "            if item.get('period', '').startswith(str(year)):\n",
    "                return item.get('v')  # assuming value is under 'v'\n",
    "        return None\n",
    "\n",
    "    def get_financial_info(self,metric_data,gaap_data):\n",
    "        financials = {\n",
    "        \"EPS\": [],\n",
    "        \"Net_Income\": [],\n",
    "        \"Gross_Profit\": [],\n",
    "        \"Revenue\": [],\n",
    "        \"Total_Assets\": [],\n",
    "        \"Total_Liabilities\": [],\n",
    "        \"Shareholders_Equity\": [],\n",
    "        \"Operating_Cash_Flow\": [],\n",
    "        \"Investing_Cash_Flow\": [],\n",
    "        \"Financing_Cash_Flow\": [],\n",
    "        \"P_E\": [],\n",
    "        \"ROA\": [],\n",
    "        \"ROE\": []\n",
    "    }\n",
    "\n",
    "        for year in self.years:\n",
    "            financials[\"EPS\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_EarningsPerShareDiluted', year))\n",
    "            financials[\"Net_Income\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_NetIncomeLoss', year))\n",
    "            financials[\"Gross_Profit\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_GrossProfit', year))\n",
    "            financials[\"Revenue\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_RevenueFromContractWithCustomerExcludingAssessedTax', year))\n",
    "            financials[\"Total_Assets\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_Assets', year))\n",
    "            financials[\"Total_Liabilities\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_Liabilities', year))\n",
    "            financials[\"Shareholders_Equity\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_StockholdersEquity', year))\n",
    "            financials[\"Operating_Cash_Flow\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_NetCashProvidedByUsedInOperatingActivities', year))\n",
    "            financials[\"Investing_Cash_Flow\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_NetCashProvidedByUsedInInvestingActivities', year))\n",
    "            financials[\"Financing_Cash_Flow\"].append(self.find_us_gaap_entry(gaap_data, 'us-gaap_NetCashProvidedByUsedInFinancingActivities', year))\n",
    "            financials[\"P_E\"].append(self.find_metric_by_year(metric_data, 'pe', year))\n",
    "            financials[\"ROA\"].append(self.find_metric_by_year(metric_data, 'roa', year))\n",
    "            financials[\"ROE\"].append(self.find_metric_by_year(metric_data, 'roe', year))\n",
    "\n",
    "        return financials\n",
    "    \n",
    "    def fmt(self, value, fmt_str):\n",
    "        return format(value, fmt_str) if value is not None else \"N/A\"\n",
    "\n",
    "    def generate_prompt(self):\n",
    "        prompt = f\"\"\" Choose a recommendation for each stock. Respond in a vector of floats between [-1,1], -1 being Short and 1 being Strong Buy. \n",
    "Make these decisions based solely on the fundamental indicators given below for each stock. Return only the vector, no explanation is needed.\n",
    " You MUST return the vector at the end in this format [company1,company2,...companyn]: [Value1,Value2,Valuen]\\n\\n\"\"\"\n",
    "        for ticker in self.tickers:\n",
    "            financials=self.data_processed[ticker]\n",
    "            partial_stats=f\"\"\"Financials for {ticker}:\\n\"\"\"\n",
    "            for i, year in enumerate(self.years):\n",
    "                partial_stats += f\"\"\"\n",
    "                Year: {year}\n",
    "                Income Statement:\n",
    "                Revenue: ${self.fmt(financials[\"Revenue\"][i], \",.0f\")}\n",
    "                Gross Profit: ${self.fmt(financials[\"Gross_Profit\"][i], \",.0f\")}\n",
    "                Net Income: ${self.fmt(financials[\"Net_Income\"][i], \",.0f\")}\n",
    "                EPS (Diluted): {self.fmt(financials[\"EPS\"][i], \".2f\")}\n",
    "\n",
    "                Balance Sheet:\n",
    "                Total Assets: ${self.fmt(financials[\"Total_Assets\"][i], \",.0f\")}\n",
    "                Total Liabilities: ${self.fmt(financials[\"Total_Liabilities\"][i], \",.0f\")}\n",
    "                Shareholders' Equity: ${self.fmt(financials[\"Shareholders_Equity\"][i], \",.0f\")}\n",
    "\n",
    "                Cash Flow:\n",
    "                Operating Cash Flow: ${self.fmt(financials[\"Operating_Cash_Flow\"][i], \",.0f\")}\n",
    "                Investing Cash Flow: ${self.fmt(financials[\"Investing_Cash_Flow\"][i], \",.0f\")}\n",
    "                Financing Cash Flow: ${self.fmt(financials[\"Financing_Cash_Flow\"][i], \",.0f\")}\n",
    "\n",
    "                Valuation and Ratios:\n",
    "                P/E Ratio: {self.fmt(financials[\"P_E\"][i], \".2f\")}\n",
    "                ROA: {self.fmt(financials[\"ROA\"][i], \".2%\")}\n",
    "                ROE: {self.fmt(financials[\"ROE\"][i], \".2%\")}\n",
    "                \"\"\"\n",
    "            prompt+=partial_stats+\"\\n\\n\"\n",
    "        prompt += \"\\nBased on this, what is your investment recommendation? Pick one action candidate.\"\n",
    "        self.prompt = prompt\n",
    "        return prompt\n",
    "\n",
    "    def generate_response(self):\n",
    "        prompt = self.prompt\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert fundamental analyst. Analyze stocks to the best of your ability.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        self.response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bcabdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class News_Analyst:\n",
    "\n",
    "    def __init__ (self,tickers, companies, start_date, end_date):\n",
    "        self.tickers=[tickers] if isinstance(tickers,str) else tickers\n",
    "        self.companies=[companies] if isinstance(companies,str) else companies\n",
    "        self.start_date=start_date\n",
    "        self.end_date=end_date\n",
    "        news_collection={}\n",
    "        for i,ticker in enumerate(self.tickers):\n",
    "            news_collection[ticker]=self.get_news_articles(ticker,companies[i])\n",
    "        self.news_collection=news_collection\n",
    "        self.generate_news_prompt()\n",
    "        \n",
    "    def get_news_articles(self,ticker,company):\n",
    "        file_path = f\"/home/f20222001/test-venv/Portfolio/sp500_news/sp500_news/{ticker}.jsonl\"\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\")\n",
    "        end_dt   = datetime.strptime(self.end_date, \"%Y-%m-%d\")\n",
    "\n",
    "        want = 10\n",
    "        titles, seen = [], set()\n",
    "\n",
    "        # 1) Local JSONL (assumed to exist)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                obj = json.loads(line)\n",
    "                title = (obj.get(\"Article_title\") or \"\").strip()\n",
    "                if not title:\n",
    "                    continue\n",
    "                article_dt = datetime.strptime(obj[\"Date\"], \"%Y-%m-%d\")\n",
    "                if start_dt <= article_dt <= end_dt and company.lower() in title.lower():\n",
    "                    if title not in seen:\n",
    "                        seen.add(title)\n",
    "                        titles.append(title)\n",
    "\n",
    "        # 2) If fewer than 10, top up with Finnhub for the same window\n",
    "        if len(titles) < want:\n",
    "            #print(\"entered\")\n",
    "            url = (\n",
    "                \"https://finnhub.io/api/v1/company-news\"\n",
    "                f\"?symbol={ticker}&from={self.start_date}&to={self.end_date}\"\n",
    "                f\"&token=d1l719pr01qt4thec1pgd1l719pr01qt4thec1q0\"\n",
    "            )\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.ok:\n",
    "                for item in (r.json() or []):\n",
    "                    title = (item.get(\"headline\") or \"\").strip()\n",
    "                    print(title)\n",
    "                    if not title or title in seen:\n",
    "                        continue\n",
    "                    ts = item.get(\"datetime\")\n",
    "                    if isinstance(ts, (int, float)):\n",
    "                        art_date = datetime.fromtimestamp(ts, tz=timezone.utc).date()\n",
    "                        if start_dt.date() <= art_date <= end_dt.date() and company.lower() in title.lower():\n",
    "                            seen.add(title)\n",
    "                            titles.append(title)\n",
    "                            if len(titles) >= want:\n",
    "                                break\n",
    "\n",
    "        # 3) Cap at 10 (randomize if overshoot)\n",
    "        if len(titles) > want:\n",
    "            titles = random.sample(titles, want)\n",
    "\n",
    "        selected_news = titles\n",
    "        return selected_news\n",
    "    \n",
    "    def generate_news_prompt(self):\n",
    "        prompt = f\"\"\" Choose a recommendation for each stock. Respond in a vector of floats between [-1,1], -1 being Short and 1 being Strong Buy. \n",
    "Make these decisions based solely on the news headlines and sentiment given below for each stock. Return only the vector, no explanation is needed.\n",
    "You MUST return the vector at the end in this format [company1,company2,...companyn].\n",
    "\n",
    "Headlines:\n",
    "\"\"\"\n",
    "        for ticker in self.tickers:\n",
    "            prompt+=f\"\"\" News for {ticker}\\n\"\"\"\n",
    "            for i, item in enumerate(self.news_collection[ticker]):\n",
    "                prompt+=item\n",
    "                prompt+='\\n'\n",
    "        prompt+=\"Based on this, what is your investment recommendation? Pick one action candidate.\"\n",
    "        self.prompt=prompt\n",
    "        return self.prompt\n",
    "    \n",
    "    def generate_response(self):\n",
    "        prompt = self.prompt\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert news and sentiment analyst. Analyze stocks to the best of your ability.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        self.response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9274b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_row(ticker_list, company_list, start_date, end_date):\n",
    "    technical_instance=Technical_Analyst(tickers=ticker_list, start_date=start_date, end_date=end_date)\n",
    "    fundamental_instance=Fundamental_Analyst(tickers=ticker_list, start_date=start_date, end_date=end_date)\n",
    "    news_instance=News_Analyst(tickers=ticker_list, companies=company_list, start_date=start_date, end_date=end_date)\n",
    "    technical_data=technical_instance.indicators_processed\n",
    "    technical_response=technical_instance.generate_response()\n",
    "    fundamental_data=fundamental_instance.data_processed\n",
    "    fundamental_response=fundamental_instance.generate_response()\n",
    "    news_response=news_instance.generate_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "503e1816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53847/3800720131.py:32: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  self.data = yf.download(self.tickers, start=self.start_date, end=self.end_date)\n",
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    }
   ],
   "source": [
    "ticker_list=[\"AAPL\", \"NVDA\", \"LMT\", \"LLY\", \"GLD\", \"USO\", \"TLT\"]\n",
    "start_date=\"2024-08-01\"\n",
    "end_date=\"2024-09-01\"\n",
    "company_list=[\"Apple\", \"Nvidia\", \"Lockheed\", \"Eli Lilly\", \"Gold\", \"Oil\", \"Bonds\"]\n",
    "technical_instance=Technical_Analyst(tickers=ticker_list, start_date=start_date, end_date=end_date)\n",
    "fundamental_instance=Fundamental_Analyst(tickers=ticker_list, start_date=start_date, end_date=end_date)\n",
    "news_instance=News_Analyst(tickers=ticker_list, companies=company_list, start_date=start_date, end_date=end_date)\n",
    "technical_data=technical_instance.indicators_processed\n",
    "technical_response=technical_instance.generate_response()\n",
    "fundamental_data=fundamental_instance.data_processed\n",
    "fundamental_response=fundamental_instance.generate_response()\n",
    "news_response=news_instance.generate_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de67a4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': [], 'NVDA': [], 'LMT': [], 'LLY': [], 'GLD': [], 'USO': [], 'TLT': []}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_instance.news_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78a62029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>SMA_15</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>Date</th>\n",
       "      <th>RSI</th>\n",
       "      <th>OBV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.129997</td>\n",
       "      <td>75.129997</td>\n",
       "      <td>75.129997</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.609999</td>\n",
       "      <td>75.569999</td>\n",
       "      <td>75.537999</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.624736</td>\n",
       "      <td>74.749932</td>\n",
       "      <td>74.841717</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.339230</td>\n",
       "      <td>73.689108</td>\n",
       "      <td>73.963463</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6511900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-05</th>\n",
       "      <td>73.531999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.648530</td>\n",
       "      <td>73.072158</td>\n",
       "      <td>73.439236</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-08</th>\n",
       "      <td>73.214000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.974286</td>\n",
       "      <td>73.193673</td>\n",
       "      <td>73.457753</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-09</th>\n",
       "      <td>72.717999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.142714</td>\n",
       "      <td>73.255437</td>\n",
       "      <td>73.456508</td>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10</th>\n",
       "      <td>72.875999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.551076</td>\n",
       "      <td>73.497630</td>\n",
       "      <td>73.580147</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-11</th>\n",
       "      <td>73.825999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.485011</td>\n",
       "      <td>74.102976</td>\n",
       "      <td>73.930317</td>\n",
       "      <td>2022-08-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7874200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12</th>\n",
       "      <td>74.514000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.652920</td>\n",
       "      <td>74.287201</td>\n",
       "      <td>74.055165</td>\n",
       "      <td>2022-08-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4924600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-15</th>\n",
       "      <td>74.381999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.055034</td>\n",
       "      <td>73.999727</td>\n",
       "      <td>73.925713</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-16</th>\n",
       "      <td>73.939999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.109400</td>\n",
       "      <td>73.448338</td>\n",
       "      <td>73.649463</td>\n",
       "      <td>2022-08-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5271700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-17</th>\n",
       "      <td>73.486000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.754444</td>\n",
       "      <td>73.173888</td>\n",
       "      <td>73.494788</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-18</th>\n",
       "      <td>73.072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.241297</td>\n",
       "      <td>73.374348</td>\n",
       "      <td>73.560192</td>\n",
       "      <td>2022-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-19</th>\n",
       "      <td>72.887999</td>\n",
       "      <td>73.644666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.514822</td>\n",
       "      <td>73.505474</td>\n",
       "      <td>73.603629</td>\n",
       "      <td>2022-08-19</td>\n",
       "      <td>47.074908</td>\n",
       "      <td>-855700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-22</th>\n",
       "      <td>73.248000</td>\n",
       "      <td>73.614666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.903807</td>\n",
       "      <td>73.727998</td>\n",
       "      <td>73.692916</td>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>46.548871</td>\n",
       "      <td>7081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-23</th>\n",
       "      <td>74.366000</td>\n",
       "      <td>73.674666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.880196</td>\n",
       "      <td>74.311243</td>\n",
       "      <td>73.942238</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>59.238522</td>\n",
       "      <td>10863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24</th>\n",
       "      <td>75.564000</td>\n",
       "      <td>73.975333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.934178</td>\n",
       "      <td>75.008009</td>\n",
       "      <td>74.255307</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>69.068531</td>\n",
       "      <td>14721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25</th>\n",
       "      <td>76.022000</td>\n",
       "      <td>74.306667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.122870</td>\n",
       "      <td>75.285407</td>\n",
       "      <td>74.420654</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>63.333321</td>\n",
       "      <td>11760800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>76.380000</td>\n",
       "      <td>74.594000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.031886</td>\n",
       "      <td>75.389949</td>\n",
       "      <td>74.522435</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>56.695639</td>\n",
       "      <td>9336200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>77.182001</td>\n",
       "      <td>74.937333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.918102</td>\n",
       "      <td>75.998964</td>\n",
       "      <td>74.809999</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>63.100004</td>\n",
       "      <td>13029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>76.910001</td>\n",
       "      <td>75.072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.435337</td>\n",
       "      <td>75.901611</td>\n",
       "      <td>74.854223</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>52.572709</td>\n",
       "      <td>8061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>75.924001</td>\n",
       "      <td>74.991334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.326793</td>\n",
       "      <td>75.388971</td>\n",
       "      <td>74.740511</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>43.032976</td>\n",
       "      <td>3523200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SMA_5     SMA_15  SMA_50      EMA_5     EMA_10     EMA_50  \\\n",
       "Date                                                                        \n",
       "2022-08-01        NaN        NaN     NaN  75.129997  75.129997  75.129997   \n",
       "2022-08-02        NaN        NaN     NaN  75.609999  75.569999  75.537999   \n",
       "2022-08-03        NaN        NaN     NaN  74.624736  74.749932  74.841717   \n",
       "2022-08-04        NaN        NaN     NaN  73.339230  73.689108  73.963463   \n",
       "2022-08-05  73.531999        NaN     NaN  72.648530  73.072158  73.439236   \n",
       "2022-08-08  73.214000        NaN     NaN  72.974286  73.193673  73.457753   \n",
       "2022-08-09  72.717999        NaN     NaN  73.142714  73.255437  73.456508   \n",
       "2022-08-10  72.875999        NaN     NaN  73.551076  73.497630  73.580147   \n",
       "2022-08-11  73.825999        NaN     NaN  74.485011  74.102976  73.930317   \n",
       "2022-08-12  74.514000        NaN     NaN  74.652920  74.287201  74.055165   \n",
       "2022-08-15  74.381999        NaN     NaN  74.055034  73.999727  73.925713   \n",
       "2022-08-16  73.939999        NaN     NaN  73.109400  73.448338  73.649463   \n",
       "2022-08-17  73.486000        NaN     NaN  72.754444  73.173888  73.494788   \n",
       "2022-08-18  73.072000        NaN     NaN  73.241297  73.374348  73.560192   \n",
       "2022-08-19  72.887999  73.644666     NaN  73.514822  73.505474  73.603629   \n",
       "2022-08-22  73.248000  73.614666     NaN  73.903807  73.727998  73.692916   \n",
       "2022-08-23  74.366000  73.674666     NaN  74.880196  74.311243  73.942238   \n",
       "2022-08-24  75.564000  73.975333     NaN  75.934178  75.008009  74.255307   \n",
       "2022-08-25  76.022000  74.306667     NaN  76.122870  75.285407  74.420654   \n",
       "2022-08-26  76.380000  74.594000     NaN  76.031886  75.389949  74.522435   \n",
       "2022-08-29  77.182001  74.937333     NaN  76.918102  75.998964  74.809999   \n",
       "2022-08-30  76.910001  75.072000     NaN  76.435337  75.901611  74.854223   \n",
       "2022-08-31  75.924001  74.991334     NaN  75.326793  75.388971  74.740511   \n",
       "\n",
       "                 Date        RSI       OBV  \n",
       "Date                                        \n",
       "2022-08-01 2022-08-01        NaN         0  \n",
       "2022-08-02 2022-08-02        NaN   2737300  \n",
       "2022-08-03 2022-08-03        NaN  -1296400  \n",
       "2022-08-04 2022-08-04        NaN  -6511900  \n",
       "2022-08-05 2022-08-05        NaN  -3372700  \n",
       "2022-08-08 2022-08-08        NaN   1056800  \n",
       "2022-08-09 2022-08-09        NaN  -1435400  \n",
       "2022-08-10 2022-08-10        NaN   3186900  \n",
       "2022-08-11 2022-08-11        NaN   7874200  \n",
       "2022-08-12 2022-08-12        NaN   4924600  \n",
       "2022-08-15 2022-08-15        NaN    478400  \n",
       "2022-08-16 2022-08-16        NaN  -5271700  \n",
       "2022-08-17 2022-08-17        NaN  -1471000  \n",
       "2022-08-18 2022-08-18        NaN   1844900  \n",
       "2022-08-19 2022-08-19  47.074908   -855700  \n",
       "2022-08-22 2022-08-22  46.548871   7081600  \n",
       "2022-08-23 2022-08-23  59.238522  10863600  \n",
       "2022-08-24 2022-08-24  69.068531  14721000  \n",
       "2022-08-25 2022-08-25  63.333321  11760800  \n",
       "2022-08-26 2022-08-26  56.695639   9336200  \n",
       "2022-08-29 2022-08-29  63.100004  13029700  \n",
       "2022-08-30 2022-08-30  52.572709   8061700  \n",
       "2022-08-31 2022-08-31  43.032976   3523200  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technical_data['USO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ab510ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[aapl,nvda,lmt,lly,gld,uso,tlt]: [0.2,-0.1,0.7,0.4,-0.3,0.5,-0.2]'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technical_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1f7e331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': {'EPS': [6.11],\n",
       "  'Net_Income': [99803000000.0],\n",
       "  'Gross_Profit': [170782000000],\n",
       "  'Revenue': [394328000000.0],\n",
       "  'Total_Assets': [352755000000],\n",
       "  'Total_Liabilities': [302083000000],\n",
       "  'Shareholders_Equity': [50672000000.0],\n",
       "  'Operating_Cash_Flow': [122151000000],\n",
       "  'Investing_Cash_Flow': [-22354000000],\n",
       "  'Financing_Cash_Flow': [-110749000000],\n",
       "  'P_E': [24.0854],\n",
       "  'ROA': [0.2829],\n",
       "  'ROE': [1.9696]},\n",
       " 'NVDA': {'EPS': [3.85],\n",
       "  'Net_Income': [9752000000.0],\n",
       "  'Gross_Profit': [17475000000.0],\n",
       "  'Revenue': [None],\n",
       "  'Total_Assets': [44187000000.0],\n",
       "  'Total_Liabilities': [17575000000.0],\n",
       "  'Shareholders_Equity': [26612000000.0],\n",
       "  'Operating_Cash_Flow': [9108000000.0],\n",
       "  'Investing_Cash_Flow': [-9830000000.0],\n",
       "  'Financing_Cash_Flow': [1865000000.0],\n",
       "  'P_E': [62.7717],\n",
       "  'ROA': [0.2207],\n",
       "  'ROE': [0.3665]},\n",
       " 'LMT': {'EPS': [21],\n",
       "  'Net_Income': [5732000000.0],\n",
       "  'Gross_Profit': [8287000000],\n",
       "  'Revenue': [None],\n",
       "  'Total_Assets': [52880000000.0],\n",
       "  'Total_Liabilities': [43614000000],\n",
       "  'Shareholders_Equity': [9266000000],\n",
       "  'Operating_Cash_Flow': [7802000000],\n",
       "  'Investing_Cash_Flow': [-1789000000],\n",
       "  'Financing_Cash_Flow': [-7070000000],\n",
       "  'P_E': [22.2428],\n",
       "  'ROA': [0.1084],\n",
       "  'ROE': [0.6186]},\n",
       " 'LLY': {'EPS': [6],\n",
       "  'Net_Income': [6244800000.0],\n",
       "  'Gross_Profit': [None],\n",
       "  'Revenue': [None],\n",
       "  'Total_Assets': [49489800000],\n",
       "  'Total_Liabilities': [None],\n",
       "  'Shareholders_Equity': [10649800000],\n",
       "  'Operating_Cash_Flow': [7084400000],\n",
       "  'Investing_Cash_Flow': [-3261600000],\n",
       "  'Financing_Cash_Flow': [-5406700000],\n",
       "  'P_E': [57.8271],\n",
       "  'ROA': [0.1262],\n",
       "  'ROE': [0.5864]},\n",
       " 'GLD': {'EPS': [None],\n",
       "  'Net_Income': [-2944530000.0],\n",
       "  'Gross_Profit': [None],\n",
       "  'Revenue': [None],\n",
       "  'Total_Assets': [50693257000],\n",
       "  'Total_Liabilities': [202797000],\n",
       "  'Shareholders_Equity': [None],\n",
       "  'Operating_Cash_Flow': [0],\n",
       "  'Investing_Cash_Flow': [None],\n",
       "  'Financing_Cash_Flow': [None],\n",
       "  'P_E': [None],\n",
       "  'ROA': [None],\n",
       "  'ROE': [None]},\n",
       " 'USO': {'EPS': [None],\n",
       "  'Net_Income': [785240277.0],\n",
       "  'Gross_Profit': [None],\n",
       "  'Revenue': [None],\n",
       "  'Total_Assets': [1982960872],\n",
       "  'Total_Liabilities': [5945534],\n",
       "  'Shareholders_Equity': [None],\n",
       "  'Operating_Cash_Flow': [None],\n",
       "  'Investing_Cash_Flow': [None],\n",
       "  'Financing_Cash_Flow': [None],\n",
       "  'P_E': [None],\n",
       "  'ROA': [None],\n",
       "  'ROE': [None]},\n",
       " 'TLT': {'EPS': [None],\n",
       "  'Net_Income': [None],\n",
       "  'Gross_Profit': [None],\n",
       "  'Revenue': [None],\n",
       "  'Total_Assets': [None],\n",
       "  'Total_Liabilities': [None],\n",
       "  'Shareholders_Equity': [None],\n",
       "  'Operating_Cash_Flow': [None],\n",
       "  'Investing_Cash_Flow': [None],\n",
       "  'Financing_Cash_Flow': [None],\n",
       "  'P_E': [None],\n",
       "  'ROA': [None],\n",
       "  'ROE': [None]}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamental_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb29c3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[aapl,nvda,lmt,lly,gld,uso,tlt]: [0.8,0.5,0.7,0.6,-1,-1,-1]'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamental_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c79e5388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.6,-0.3,0,0,-0.1,0,0]'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cde1f9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': ['Why Apple Stock Jumped 18.9% in July',\n",
       "  'One Put, One Call Option To Know About for Apple',\n",
       "  \"Apple supplier Foxconn's Q2 profit up nearly 12%\",\n",
       "  'EXCLUSIVE-Tinder-owner Match ups antitrust pressure on Apple in India with new case',\n",
       "  'U.S. Justice Department in early stages of drafting possible antitrust suit against Apple -Politico',\n",
       "  '1 Metric That Apple Investors Should Stop Worrying About',\n",
       "  'Q2 Earnings Scorecard and Research Reports for Apple, Chevron & Toyota',\n",
       "  'Apple suppliers to make Apple Watch and MacBook in Vietnam - Nikkei',\n",
       "  'Is Apple Stock a Buy After Its Latest Earnings?',\n",
       "  'Is Most-Watched Stock Apple Inc. (AAPL) Worth Betting on Now?'],\n",
       " 'NVDA': ['Wall St trades mixed on Fed tightening fears, Nvidia weighs',\n",
       "  'Intel and AMD Earnings Share Great Insight for Nvidia Investors',\n",
       "  'Nvidia expects second-quarter revenue to drop on gaming weakness',\n",
       "  'This Is Why AMD and Nvidia Are Down Today',\n",
       "  'US STOCKS-Wall Street ends sharply up, fueled by Nvidia and Amazon',\n",
       "  'Stock Market Today: Dow Jones, S&P 500 Rally; Nvidia Falls Following Revenue Warning',\n",
       "  'Nvidia: Despite Gaming Weakness, Risk-Reward Attractive Right Now, Says Top Analyst',\n",
       "  'Nvidia Stock Drops on Weak Gaming Sales -- Is It Time to Sell This Growth Stock?',\n",
       "  '3 Things About Nvidia That Smart Investors Know',\n",
       "  '1 Green Flag and 1 Red Flag for Nvidia After a Tough Earnings Report'],\n",
       " 'LMT': [],\n",
       " 'LLY': [],\n",
       " 'GLD': ['PRECIOUS-Gold tepid on dollar strength; focus on Jackson Hole symposium',\n",
       "  'PRECIOUS-Gold firms near one-month peak on softer dollar, slowdown worries',\n",
       "  'PRECIOUS-Gold set for fifth monthly fall as U.S. rate-hike prospects mute appeal',\n",
       "  'Gold ETFs Are On a Losing Streak',\n",
       "  'PRECIOUS-Gold flat as investors await cues from Fed minutes',\n",
       "  'PRECIOUS-Gold edges higher as dollar slips from 20-year high',\n",
       "  'Time for Inverse Gold ETFs?',\n",
       "  'PRECIOUS-Gold rebounds as dollar retreat offsets higher bond yields',\n",
       "  'PRECIOUS-Gold falls as U.S. dollar, yields rise on hawkish Fed comments',\n",
       "  'PRECIOUS-Gold gains as dollar, yields retreat after Fed minutes'],\n",
       " 'USO': ['Time for Oil & Gas ETFs for 2023?',\n",
       "  'Oil ETFs Slide on Weakening Chinese Economy',\n",
       "  'Oil ETFs Gain on Optimistic Demand Outlook',\n",
       "  'Oil ETFs Slide as Americans Cut Back on Driving'],\n",
       " 'TLT': []}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_instance.news_collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
