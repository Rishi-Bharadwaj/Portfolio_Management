{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "05acf551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import yfinance as yf\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,pipeline\n",
    "import torch\n",
    "model_id = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "torch.cuda.set_device(3)  # Sets default to GPU 0\n",
    "device=torch.device(\"cuda:3\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map={\"\": 3},             # auto-distributes across GPUs\n",
    "    torch_dtype=\"auto\",            # picks bf16 or fp16 depending on availability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d29c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fundamental_analyst:\n",
    "\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "        start_year = datetime.strptime(start_date, \"%Y-%m-%d\").year\n",
    "        end_year = datetime.strptime(end_date, \"%Y-%m-%d\").year\n",
    "        self.years = list(range(start_year, end_year + 1))\n",
    "\n",
    "        self.get_data()\n",
    "        self.get_financial_info()\n",
    "        self.generate_prompt()\n",
    "        \n",
    "    def get_data(self):\n",
    "        api_key = \"d1l719pr01qt4thec1pgd1l719pr01qt4thec1q0\"\n",
    "        url = f\"https://finnhub.io/api/v1/stock/metric?symbol=AAPL&token={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        self.metric_data=response.json()\n",
    "        url = f\"https://finnhub.io/api/v1/stock/financials-reported?symbol=AAPL&token={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        self.gaap_data=response.json()\n",
    "\n",
    "    def find_us_gaap_entry(self, parameter, year):\n",
    "        for dic in self.gaap_data['data']:\n",
    "            if dic.get('year') == year:\n",
    "                for section in ['ic', 'bs', 'cf']:  # income statement, balance sheet, cash flow\n",
    "                    for entry in dic.get('report', {}).get(section, []):\n",
    "                        if parameter in entry.values():\n",
    "                            return entry.get('value')\n",
    "        return None\n",
    "\n",
    "    def find_metric_by_year(self, parameter, year):\n",
    "        series = self.metric_data.get('series', {}).get('annual', {}).get(parameter, [])\n",
    "        for item in series:\n",
    "            if item.get('period', '').startswith(str(year)):\n",
    "                return item.get('v')  # assuming value is under 'v'\n",
    "        return None\n",
    "\n",
    "    def get_financial_info(self):\n",
    "        self.EPS = []\n",
    "        self.Net_Income = []\n",
    "        self.Gross_Profit = []\n",
    "        self.Revenue = []\n",
    "        self.Total_Assets = []\n",
    "        self.Total_Liabilities = []\n",
    "        self.Shareholders_Equity = []\n",
    "        self.Free_Cash_Flow = []\n",
    "        self.Operating_Cash_Flow = []\n",
    "        self.Investing_Cash_Flow = []\n",
    "        self.Financing_Cash_Flow = []\n",
    "        self.P_E = []\n",
    "        self.ROA = []\n",
    "        self.ROE = []\n",
    "\n",
    "        for year in self.years:\n",
    "            self.EPS.append(self.find_us_gaap_entry('us-gaap_EarningsPerShareDiluted', year))\n",
    "            self.Net_Income.append(self.find_us_gaap_entry('us-gaap_NetIncomeLoss', year))\n",
    "            self.Gross_Profit.append(self.find_us_gaap_entry('us-gaap_GrossProfit', year))\n",
    "            self.Revenue.append(self.find_us_gaap_entry('us-gaap_RevenueFromContractWithCustomerExcludingAssessedTax', year))\n",
    "            self.Total_Assets.append(self.find_us_gaap_entry('us-gaap_Assets', year))\n",
    "            self.Total_Liabilities.append(self.find_us_gaap_entry('us-gaap_Liabilities', year))\n",
    "            self.Shareholders_Equity.append(self.find_us_gaap_entry('us-gaap_StockholdersEquity', year))\n",
    "            self.Operating_Cash_Flow.append(self.find_us_gaap_entry('us-gaap_NetCashProvidedByUsedInOperatingActivities', year))\n",
    "            self.Investing_Cash_Flow.append(self.find_us_gaap_entry('us-gaap_NetCashProvidedByUsedInInvestingActivities', year))\n",
    "            self.Financing_Cash_Flow.append(self.find_us_gaap_entry('us-gaap_NetCashProvidedByUsedInFinancingActivities', year))\n",
    "            self.P_E.append(self.find_metric_by_year('pe', year))\n",
    "            self.ROA.append(self.find_metric_by_year('roa', year))\n",
    "            self.ROE.append(self.find_metric_by_year('roe', year))\n",
    "\n",
    "    \n",
    "    def generate_prompt(self):\n",
    "        prompt = f\"\"\"\n",
    "    Pretend that you are a fundamental investment analyst. Analyze the financial performance of {self.ticker} and give a recommendation: Strong Buy, Buy, Hold, Sell, or Short. \n",
    "    Justify your decision in 4–6 bullet points using financial reasoning. Consider all the financial information shared. Only use the numerical data given. \n",
    "    Do not add assumptions about company operations, reputation, or strategy.\n",
    "\n",
    "    Financials for {self.ticker}:\\n\n",
    "    \"\"\"\n",
    "        for i, year in enumerate(self.years):\n",
    "            prompt += f\"\"\"\n",
    "    Year: {year}\n",
    "    Income Statement:\n",
    "    Revenue: ${self.Revenue[i]:,.0f}\n",
    "    Gross Profit: ${self.Gross_Profit[i]:,.0f}\n",
    "    Net Income: ${self.Net_Income[i]:,.0f}\n",
    "    EPS (Diluted): {self.EPS[i]:.2f}\n",
    "\n",
    "    Balance Sheet:\n",
    "    Total Assets: ${self.Total_Assets[i]:,.0f}\n",
    "    Total Liabilities: ${self.Total_Liabilities[i]:,.0f}\n",
    "    Shareholders' Equity: ${self.Shareholders_Equity[i]:,.0f}\n",
    "\n",
    "    Cash Flow:\n",
    "    Operating Cash Flow: ${self.Operating_Cash_Flow[i]:,.0f}\n",
    "    Investing Cash Flow: ${self.Investing_Cash_Flow[i]:,.0f}\n",
    "    Financing Cash Flow: ${self.Financing_Cash_Flow[i]:,.0f}\n",
    "\n",
    "    Valuation and Ratios:\n",
    "    P/E Ratio: {self.P_E[i]:.2f}\n",
    "    ROA: {self.ROA[i]:.2%}\n",
    "    ROE: {self.ROE[i]:.2%}\n",
    "\n",
    "    \"\"\"\n",
    "        prompt += \"\\nBased on this, what is your investment recommendation? Pick one action candidate.\"\n",
    "        self.prompt = prompt\n",
    "        return prompt\n",
    "\n",
    "        \n",
    "    def generate_response(self):\n",
    "        generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "        outputs = generator(\n",
    "            self.prompt,\n",
    "            max_new_tokens=500,         # Reduced for memory efficiency\n",
    "            do_sample=True,\n",
    "            temperature=0.4,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            # Memory efficient generation settings\n",
    "            num_beams=1,                # No beam search to save memory\n",
    "            #early_stopping=True,\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        full_text = outputs[0]['generated_text']\n",
    "\n",
    "        response_only = full_text[len(self.prompt):].strip()\n",
    "        return response_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c51bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class technical_analyst:\n",
    "\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.generate_df()\n",
    "        self.generate_indicators()\n",
    "        self.generate_technical_prompt()\n",
    "        \n",
    "    def generate_df(self):\n",
    "        self.data = yf.download(self.ticker, start=self.start_date, end=self.end_date)\n",
    "\n",
    "    def compute_rsi(self, close, period=14):\n",
    "        delta = close.diff()\n",
    "\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=period).mean()\n",
    "        avg_loss = loss.rolling(window=period).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def compute_obv(self, close, volume):\n",
    "        direction = close.diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "        obv = (volume * direction).fillna(0).cumsum()\n",
    "        return obv\n",
    "    \n",
    "    def generate_indicators(self):\n",
    "        temp=pd.DataFrame()\n",
    "        temp[\"SMA_5\"] = self.data['Close'][self.ticker].rolling(5).mean()\n",
    "        temp[\"SMA_15\"] = self.data['Close'][self.ticker].rolling(15).mean()\n",
    "        temp[\"SMA_50\"] = self.data['Close'][self.ticker].rolling(50).mean()\n",
    "\n",
    "        temp['EMA_5'] = self.data['Close'][self.ticker].ewm(span=5).mean()\n",
    "        temp['EMA_10'] = self.data['Close'][self.ticker].ewm(span=10).mean()\n",
    "        temp['EMA_50'] = self.data['Close'][self.ticker].ewm(span=50).mean()\n",
    "        temp[\"Date\"] = self.data['Close'][self.ticker].index\n",
    "        temp[\"RSI\"]=self.compute_rsi(self.data['Close'][self.ticker])\n",
    "        temp[\"OBV\"]=self.compute_obv(self.data['Close'][self.ticker], self.data['Volume'][self.ticker])\n",
    "        self.indicator_df=temp\n",
    "\n",
    "    def generate_technical_prompt(self):\n",
    "        latest = self.indicator_df.iloc[-1]\n",
    "        prompt = f\"\"\"\n",
    "You are a technical investment analyst. Analyze the recent technical performance of {self.ticker} and give an investment recommendation.\n",
    "\n",
    "Your task:\n",
    "Choose one of the following recommendations: Strong Buy, Buy, Hold, Sell, or Short.\n",
    "Justify your choice using 4–6 bullet points based only on the indicators below.\n",
    "You MUST respond in natural human language. Do NOT include any code or formulas.\n",
    "\n",
    "Technical Indicators for {self.ticker} (most recent data point):\n",
    "\n",
    "SMA 5: {latest['SMA_5']:.2f}\n",
    "SMA 15: {latest['SMA_15']:.2f}\n",
    "SMA 50: {latest['SMA_50']:.2f}\n",
    "\n",
    "EMA 5: {latest['EMA_5']:.2f}\n",
    "EMA 10: {latest['EMA_10']:.2f}\n",
    "EMA 50: {latest['EMA_50']:.2f}\n",
    "\n",
    "RSI: {latest['RSI']:.2f}\n",
    "OBV: {latest['OBV']:,.0f}\n",
    "\n",
    "Based on this, what is your investment recommendation? Pick one action candidate.\n",
    "\"\"\"\n",
    "        self.prompt=prompt\n",
    "        return self.prompt \n",
    "    \n",
    "    def generate_response(self):\n",
    "        generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "        outputs = generator(\n",
    "            self.prompt,\n",
    "            max_new_tokens=1000,         # Reduced for memory efficiency\n",
    "            do_sample=True,\n",
    "            temperature=0.4,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            # Memory efficient generation settings\n",
    "            num_beams=1,                # No beam search to save memory\n",
    "            #early_stopping=True,\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        full_text = outputs[0]['generated_text']\n",
    "\n",
    "        response_only = full_text[len(self.prompt):].strip()\n",
    "        return response_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class news_analyst:\n",
    "\n",
    "    def __init__ (self,ticker, company):\n",
    "        self.ticker=ticker\n",
    "        self.company=company\n",
    "        #self.get_news_articles()\n",
    "        # self.generate_news_prompt()\n",
    "        \n",
    "    def get_articles_in_date_range(self, start_date, end_date):\n",
    "\n",
    "        file_path = f\"/home/f20222001/test-venv/Portfolio/sp500_news/sp500_news/{self.ticker}.jsonl\"\n",
    "        start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_dt   = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "        results = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                obj = json.loads(line)\n",
    "                try:\n",
    "                    article_dt = datetime.strptime(obj[\"Date\"], \"%Y-%m-%d\")\n",
    "                    title = obj.get(\"Article_title\", \"\")\n",
    "                except (KeyError, ValueError):\n",
    "                    continue\n",
    "                \n",
    "                if start_dt <= article_dt <= end_dt and self.company.lower() in title.lower():\n",
    "                    results.append(obj['Article_title'])\n",
    "        if len(results) > 10:\n",
    "            results = random.sample(results, 10)\n",
    "    \n",
    "        return results\n",
    "\n",
    "    \n",
    "    def generate_news_prompt(self):\n",
    "        prompt = f\"\"\"\n",
    "Pretend that you are a sentiment and headlines investment analyst. Analyze the recent technical performance of {self.ticker} and give a recommendation: Strong Buy, Buy, Hold, Sell, or Short. \n",
    "Justify your decision in 4–6 bullet points using sentiment analysis. Only use the headlines given. \n",
    "Do not add assumptions about company fundamentals, operations, or strategy.\n",
    "\n",
    "Headlines:\n",
    "\"\"\"\n",
    "        for i, item in enumerate(self.selected_news):\n",
    "            prompt+=item['headline']\n",
    "            prompt+='\\n'\n",
    "        prompt+=\"Based on this, what is your investment recommendation? Pick one action candidate.\"\n",
    "        self.prompt=prompt\n",
    "        return self.prompt\n",
    "    \n",
    "    def generate_response(self):\n",
    "        generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "        outputs = generator(\n",
    "            self.prompt,\n",
    "            max_new_tokens=500,         # Reduced for memory efficiency\n",
    "            do_sample=True,\n",
    "            temperature=0.4,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            # Memory efficient generation settings\n",
    "            num_beams=1,                # No beam search to save memory\n",
    "            #early_stopping=True,\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        full_text = outputs[0]['generated_text']\n",
    "\n",
    "        response_only = full_text[len(self.prompt):].strip()\n",
    "        return response_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48b3d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funda=fundamental_analyst('NVDA',years=[2023,2024])\n",
    "# print(funda.prompt)\n",
    "# funda_analysis=funda.generate_response()\n",
    "# print(\"Response\")\n",
    "# print(funda_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f20c0729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Down 28% in 2022, Is Apple Stock a Buy for 2023?']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news=news_analyst('AAPL','apple')\n",
    "news.get_articles_in_date_range(start_date=\"2023-01-01\",end_date=\"2023-01-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "accbdf0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'news_analyst' object has no attribute 'headlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnews\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheadlines\u001b[49m[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mAttributeError\u001b[39m: 'news_analyst' object has no attribute 'headlines'"
     ]
    }
   ],
   "source": [
    "print(news.headlines[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
