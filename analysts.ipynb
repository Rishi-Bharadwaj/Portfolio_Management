{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05acf551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f20222001/test-venv/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import yfinance as yf\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,pipeline\n",
    "import torch\n",
    "model_id = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "torch.cuda.set_device(3)  # Sets default to GPU 0\n",
    "device=torch.device(\"cuda:3\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map={\"\": 3},             # auto-distributes across GPUs\n",
    "    torch_dtype=\"auto\",            # picks bf16 or fp16 depending on availability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d29c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fundamental_analyst:\n",
    "\n",
    "    def __init__ (self, ticker):\n",
    "        self.ticker=ticker\n",
    "    \n",
    "    def get_financial_info(self):\n",
    "        ticker = yf.Ticker(self.ticker)\n",
    "        self.income_stmt = ticker.financials\n",
    "        self.balance_sheet = ticker.balance_sheet\n",
    "        self.cash_flow = ticker.cashflow\n",
    "        self.info = ticker.info\n",
    "        self.year=self.income_stmt.columns[0]\n",
    "        self.EPS=self.income_stmt[self.year][\"Diluted EPS\"]\n",
    "        self.Net_Income=self.income_stmt[self.year][\"Net Income\"]\n",
    "        self.Gross_Profit=self.income_stmt[self.year][\"Gross Profit\"]\n",
    "        self.Revenue=self.income_stmt[self.year][\"Total Revenue\"]\n",
    "        self.Total_Assets=self.balance_sheet[self.year][\"Total Assets\"]\n",
    "        self.Total_Liabilities=self.balance_sheet[self.year][\"Total Liabilities Net Minority Interest\"]\n",
    "        self.Shareholders_Equity=self.balance_sheet[self.year][\"Stockholders Equity\"]\n",
    "        self.Free_Cash_Flow=self.cash_flow[self.year][\"Free Cash Flow\"]\n",
    "        self.Investing_Cash_Flow=self.cash_flow[self.year][\"Investing Cash Flow\"]\n",
    "        self.Financing_Cash_Flow=self.cash_flow[self.year][\"Financing Cash Flow\"]\n",
    "        self.Operating_Cash_Flow=self.cash_flow[self.year][\"Operating Cash Flow\"]\n",
    "        self.P_E=ticker.info['trailingPE']\n",
    "        self.ROA=ticker.info['returnOnAssets']\n",
    "        self.ROE=ticker.info['returnOnEquity']\n",
    "    \n",
    "    def generate_prompt(self):\n",
    "        prompt = f\"\"\"\n",
    "You are a fundamental investment analyst. Analyze the financial performance of {self.ticker} and give a recommendation: Strong Buy, Buy, Hold, Sell, or Short. \n",
    "Justify your decision in 4–6 bullet points using financial reasoning. Consider all the financial information shared. Only use the numerical data given. \n",
    "Do not add assumptions about company operations, reputation, or strategy.\n",
    "\n",
    "Financials for {self.ticker}:\n",
    "\n",
    "Income Statement:\n",
    "Revenue: ${self.Revenue:,.0f}\n",
    "Gross Profit: ${self.Gross_Profit:,.0f}\n",
    "Net Income: ${self.Net_Income:,.0f}\n",
    "EPS (Diluted): {self.EPS:.2f}\n",
    "\n",
    "Balance Sheet:\n",
    "Total Assets: ${self.Total_Assets:,.0f}\n",
    "Total Liabilities: ${self.Total_Liabilities:,.0f}\n",
    "Shareholders' Equity: ${self.Shareholders_Equity:,.0f}\n",
    "\n",
    "Cash Flow:\n",
    "Operating Cash Flow: ${self.Operating_Cash_Flow:,.0f}\n",
    "Free Cash Flow: ${self.Free_Cash_Flow:,.0f}\n",
    "Investing Cash Flow: ${self.Investing_Cash_Flow:,.0f}\n",
    "Financing Cash Flow: ${self.Financing_Cash_Flow:,.0f}\n",
    "\n",
    "Valuation and Ratios:\n",
    "P/E Ratio: {self.P_E:.2f}\n",
    "ROA: {self.ROA:.2%}\n",
    "ROE: {self.ROE:.2%}\n",
    "\n",
    "Based on this, what is your investment recommendation? Pick one action candidate.\"\"\"\n",
    "        self.prompt=prompt\n",
    "        \n",
    "    def generate_response(self):\n",
    "        generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "        outputs = generator(\n",
    "            self.prompt,\n",
    "            max_new_tokens=500,         # Reduced for memory efficiency\n",
    "            do_sample=True,\n",
    "            temperature=0.4,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            # Memory efficient generation settings\n",
    "            num_beams=1,                # No beam search to save memory\n",
    "            #early_stopping=True,\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        generated_text = outputs[0]['generated_text']\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c51bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class technical_analyst:\n",
    "\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker=ticker\n",
    "    \n",
    "    def generate_df(self):\n",
    "        self.data=yf.download(self.ticker, period='1y')\n",
    "\n",
    "    def compute_rsi(close, period=14):\n",
    "        delta = close.diff()\n",
    "\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=period).mean()\n",
    "        avg_loss = loss.rolling(window=period).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def compute_obv(close, volume):\n",
    "        direction = close.diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "        obv = (volume * direction).fillna(0).cumsum()\n",
    "        return obv\n",
    "    \n",
    "    def generate_indicators(self):\n",
    "        temp=pd.DataFrame()\n",
    "        temp[\"SMA_5\"] = self.data[\"Close\"].rolling(5).mean()\n",
    "        temp[\"SMA_15\"] = self.data[\"Close\"].rolling(15).mean()\n",
    "        temp[\"SMA_50\"] = self.data[\"Close\"].rolling(50).mean()\n",
    "\n",
    "        temp['EMA_5'] = self.data['Close'].ewm(span=5).mean()\n",
    "        temp['EMA_10'] = self.data['Close'].ewm(span=10).mean()\n",
    "        temp['EMA_50'] = self.data['Close'].ewm(span=50).mean()\n",
    "        temp[\"Date\"] = self.data['Close'].index\n",
    "        temp[\"RSI\"]=self.compute_rsi(self.data['Close'])\n",
    "        temp[\"OBV\"]=self.compute_obv(self.data['Close'], self.data['Volume'])\n",
    "        self.indicator_df=temp\n",
    "\n",
    "    def create_technical_prompt(self):\n",
    "        latest = self.indicator_df.iloc[-1]\n",
    "        prompt = f\"\"\"\n",
    "        You are a technical investment analyst. Analyze the recent technical performance of {self.ticker} and give a recommendation: Strong Buy, Buy, Hold, Sell, or Short. \n",
    "        Justify your decision in 4–6 bullet points using technical analysis. Only use the numerical data given. \n",
    "        Do not add assumptions about company fundamentals, operations, or strategy.\n",
    "\n",
    "        Technical Indicators for {self.ticker} (most recent data point):\n",
    "\n",
    "        - SMA 5: {latest['SMA_5']:.2f}\n",
    "        - SMA 15: {latest['SMA_15']:.2f}\n",
    "        - SMA 50: {latest['SMA_50']:.2f}\n",
    "\n",
    "        - EMA 5: {latest['EMA_5']:.2f}\n",
    "        - EMA 10: {latest['EMA_10']:.2f}\n",
    "        - EMA 50: {latest['EMA_50']:.2f}\n",
    "\n",
    "        - RSI: {latest['RSI']:.2f}\n",
    "        - OBV: {latest['OBV']:,.0f}\n",
    "\n",
    "        Based on this, what is your investment recommendation? Pick one action candidate.\n",
    "        \"\"\"\n",
    "        self.prompt=prompt\n",
    "\n",
    "    def generate_response(self):\n",
    "        generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "        outputs = generator(\n",
    "            self.prompt,\n",
    "            max_new_tokens=500,         # Reduced for memory efficiency\n",
    "            do_sample=True,\n",
    "            temperature=0.4,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            # Memory efficient generation settings\n",
    "            num_beams=1,                # No beam search to save memory\n",
    "            #early_stopping=True,\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        generated_text = outputs[0]['generated_text']\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class news_analyst:\n",
    "\n",
    "    def __init__ (self,ticker):\n",
    "        self.ticker=ticker\n",
    "    \n",
    "    def get_news_articles(self):\n",
    "        to_date = datetime.today().date()\n",
    "\n",
    "        from_date = to_date - timedelta(days=7)\n",
    "\n",
    "        from_str = from_date.strftime('%Y-%m-%d')\n",
    "        to_str = to_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        symbol = \"AAPL\"\n",
    "        api_key = \"d1l719pr01qt4thec1pgd1l719pr01qt4thec1q0\"\n",
    "        url = f\"https://finnhub.io/api/v1/company-news?symbol={symbol}&from={from_str}&to={to_str}&token={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        news = response.json()\n",
    "        filtered_news = [\n",
    "            item for item in news\n",
    "            if \"apple\" in item['headline'].lower()\n",
    "        ]\n",
    "        self.selected_news = random.sample(filtered_news, k=min(10, len(filtered_news)))\n",
    "    \n",
    "    def generate_news_prompt(self):\n",
    "        prompt = f\"\"\"\n",
    "You are a sentiment and headlines investment analyst. Analyze the recent technical performance of {t} and give a recommendation: Strong Buy, Buy, Hold, Sell, or Short. \n",
    "Justify your decision in 4–6 bullet points using sentiment analysis. Only use the headlines given. \n",
    "Do not add assumptions about company fundamentals, operations, or strategy.\n",
    "Headlines:\n",
    "\"\"\"\n",
    "        for i, item in enumerate(self.selected_news):\n",
    "            prompt+=item['headline']\n",
    "            prompt+='\\n'\n",
    "        prompt+=\"Based on this, what is your investment recommendation? Pick one action candidate.\"\n",
    "        self.prompt=prompt\n",
    "\n",
    "    def generate_response(self):\n",
    "        generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "        outputs = generator(\n",
    "            self.prompt,\n",
    "            max_new_tokens=500,         # Reduced for memory efficiency\n",
    "            do_sample=True,\n",
    "            temperature=0.4,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            # Memory efficient generation settings\n",
    "            num_beams=1,                # No beam search to save memory\n",
    "            #early_stopping=True,\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        generated_text = outputs[0]['generated_text']\n",
    "        return generated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
